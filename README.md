# Moral Judgment LLM Evaluation
This repository contains the papers and resources of our survey *Assessing Moral Judgment by Large Language Models – A Survey on Available Datasets*. 

Note that papers may appear in multiple sections depending on their research design.

## Existing benchmark datasets on moral judgment by LLMs:
![Flussdiagramm - Rahmen 6](https://github.com/user-attachments/assets/b7ef94e1-c0ed-4258-aa0e-c34d6a5c0ebc)

## Predecessors to our work
**[Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research](https://doi.org/10.18653/v1/2023.findings-emnlp.368)**. Karina Vida, Judith Simon, and Anne Lauscher. 2023. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 5534–5554, Singapore. Association for Computational Linguistics.

**[Towards Measuring and Modeling “Culture” in LLMs: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.882)**. Muhammad Farid Adilazuarda, Sagnik Mukherjee, Pradhyumna Lavania, Siddhant Shivdutt Singh, Alham Fikri Aji, Jacki O’Neill, Ashutosh Modi, and Monojit Choudhury. 2024. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 15763–15784, Miami, Florida, USA. Association for Computational Linguistics.

## Background to Machine Ethics
**[Implementation of Moral Uncertainty in Intelligent Machines](https://doi.org/10.1007/s11023-017-9448-z)**. Kyle Bogosian. 2017. Minds Mach., 27(4):591–608.

**[Artificial Intelligence, Values, and Alignment](https://doi.org/10.1007/s11023-020-09539-2)**. Iason Gabriel. 2020. Minds and Machines, 30(3):411–437. 

**[Computational ethics](https://doi.org/10.1016/j.tics.2022.02.009)**. Edmond Awad, Sydney Levine, Michael Anderson, Susan Leigh Anderson, Vincent Conitzer, M.J. Crockett, Jim A.C. Everett, Theodoros Evgeniou, Alison Gopnik, Julian C. Jamison, Tae Wan Kim, S. Matthew Liao, Michelle N. Meyer, John Mikhail, Kweku Opoku-Agyemang, Jana Schaich Borg, Juliana Schroeder, Walter Sinnott-Armstrong, Marija Slavkovik, and Josh B. Tenenbaum. 2022. Trends in Cognitive Sciences, 26(5):388–405.

**[On the Machine Learning of Ethical Judgments from Natural Language](https://doi.org/10.18653/v1/2022.naacl-main.56)**. Zeerak Talat, Hagen Blix, Josef Valvoda, Maya Indira Ganesh, Ryan Cotterell, and Adina Williams. 2022. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 769–779, Seattle, United States. Association for Computational Linguistics.

**[Position: social choice should guide AI alignment in dealing with diverse human feedback](https://dl.acm.org/doi/10.5555/3692070.3692441)**. Vincent Conitzer, Rachel Freedman, Jobst Heitzig, Wesley H. Holliday, Bob M. Jacobs, Nathan Lambert, Milan Mossé, Eric Pacuit, Stuart Russell, Hailey Schoelkopf, Emanuel Tewolde, and William S. Zwicker. 2025. In Proceedings of the 41st International Conference on Machine Learning, ICML’24. JMLR.org.

## Datasets Curated for LLMs 
### Focus on Crowdsourcing
**[Social Chemistry 101: Learning to Reason about Social and Moral Norms](https://doi.org/10.18653/v1/2020.emnlp-main.48)**. Maxwell Forbes, Jena D. Hwang, Vered Shwartz, Maarten Sap, and Yejin Choi. 2020. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 653–670, Online. Association for Computational Linguistics.

**[Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences.](https://doi.org/10.18653/v1/2021.emnlp-main.54)**. Denis Emelin, Ronan Le Bras, Jena D. Hwang, Maxwell Forbes, and Yejin Choi. 2021. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 698–718, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.
  
**[Aligning AI With Shared Human Values](https://iclr.cc/virtual/2021/poster/2960)**. Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt. 2021a. Proceedings of the International Conference on Learning Representations (ICLR).

**[Aligning AI With Shared Human Values](http://arxiv.org/abs/2008.02275)**. Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt. 2023. arXiv:2008.02275v6.

**[Measuring Massive Multitask Language Understanding](http://arxiv.org/abs/2009.03300)**. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021b. arXiv:2009.03300v3.

**[SCRUPLES: A Corpus of Community Ethical Judgments on 32,000 Real-life Anecdotes](https://doi.org/10.1609/aaai.v35i15.17589)**. Nicholas Lourie, Ronan Le Bras, and Yejin Choi. 2021. In The Thirty-Fifth AAAI Conferenceon Artificial Intelligence(AAAI-21), pages 13470–13479. Association for the Advancement of Artificial Intelligence.

**[Can Machines Learn Morality? The Delphi Experiment](http://arxiv.org/abs/2110.07574)**. Liwei Jiang, Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Jenny Liang, Jesse Dodge, Keisuke Sakaguchi, Maxwell Forbes, Jon Borchardt, Saadia Gabriel, Yulia Tsvetkov, Oren Etzioni, Maarten Sap, Regina Rini, and Yejin Choi. 2022. arXiv:2110.07574v2.

**[Aligning Generative Language Models with Human Values](https://doi.org/10.18653/v1/2022.findings-naacl.18)**. Ruibo Liu, Ge Zhang, Xinyu Feng, and Soroush Vosoughi. 2022. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 241–252, Seattle, United States. Association for Computational Linguistics.
  
**[Let’s Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning](http://arxiv.org/abs/2306.14308)**. Xiao Ma, Swaroop Mishra, Ahmad Beirami, Alex Beutel, and Jilin Chen. 2023. arXiv:2306.14308.
  
**[Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity](https://doi.org/10.18653/v1/2023.acl-srw.40)**. Gabriel Simmons. 2023. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop), pages 282–297, Toronto, Canada. Association for Computational Linguistics.

**[Beyond the imitation game: Quantifying and extrapolating the capabilities of language models](http://arxiv.org/abs/2206.04615)**. Aarohi Srivastava et al. 2023. arXiv:2206.04615v3.

**[Towards Theory-based Moral AI: Moral AI with Aggregating Models Based on Normative Ethical Theory](https://ceur-ws.org/Vol-3547/paper3.pdf)**. Masashi Takeshita, Rzepka Rafal, and Kenji Araki. 2023. In Ethics and Trust in Human-AI Collaboration: Socio-Technical Approaches, August 21, 2023, Macao, China. CEUR Workshop Proceedings.  
  
**[Position: TrustLLM: Trustworthiness in large language models](https://proceedings.mlr.press/v235/huang24x.html)**. Huang et al. 2024. 2024. In Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 20166–20270. PMLR.

**[EAI: Emotional Decision-Making of LLMs in Strategic Games and Ethical Dilemmas](https://proceedings.neurips.cc/paper_files/paper/2024/file/611e84703eac7cc03f78339df8aae2ed-Paper-Conference.pdf)**. Mikhail Mozikov, Nikita Severin, Valeria Bodishtianu, Maria Glushanina, Ivan Nasonov, Daniil Orekhov, Pekhotin Vladislav, Ivan Makovetskiy, Mikhail Baklashkin, Vasily Lavrentyev, Akim Tsvigun, Denis Turdakov, Tatiana Shavrina, Andrey Savchenko, and Ilya Makarov. 2024. In Advances in Neural Information Processing Systems, volume 37, pages 53969–54002. Curran Associates, Inc.

**[Multilingual Massive Multitask Language Understanding (MMMLU)](https://huggingface.co/datasets/openai/MMMLU)**. OpenAI. 2024. 
  
**[Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation](http://arxiv.org/abs/2412.03304)**. Shivalika Singh, Angelika Romanou, Clémentine Fourrier, David I. Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Wei-Yin Ko, Madeline Smith, Antoine Bosselut, Alice Oh, Andre F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza Ermis, and Sara Hooker. 2024. arXiv:2412.03304.

**[Beyond Labels: Aligning Large Language Models with Human-Like Reasoning](https://link.springer.com/chapter/10.1007/978-3-031-78172-8_16)**. Muhammad Rafsan Kabir, Rafeed Mohammad Sultan, Ihsanul Haque Asif, Jawad Ibn Ahad, Fuad Rahman, Mohammad Ruhul Amin, Nabeel Mohammed, and Shafin Rahman. 2025. In Pattern Recognition, pages 239–254, Cham. Springer Nature Switzerland.
  
### Synthetically Generated Data
**[The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems](https://doi.org/10.18653/v1/2022.acl-long.261)**. Caleb Ziems, Jane Yu, Yi-Chia Wang, Alon Halevy, and Diyi Yang. 2022. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3755–3773, Dublin, Ireland. Association for Computational Linguistics.

**[Off The Rails: Procedural Dilemma Generation for Moral Reasoning](https://neurips.cc/virtual/2023/77057)**. Jan-Philipp Fränken, Ayesha Khawaja, Kanishk Gandhi, Jared Moore, Noah D. Goodman, and Tobias Gerstenberg. 2023. In AI Meets Moral Philosophy and Moral Psychology Workshop (NeurIPS 2023).

**[Understanding social reasoning in language models with language models](https://doi.org/https://dl.acm.org/doi/10.5555/3666122.3666717)**. Kanishk Gandhi, J.-Philipp Fränken, Tobias Gerstenberg, and Noah D. Goodman. 2023. In Proceedings of the 37th International Conference on Neural Information Processing Systems, NeurIPS ’23, Red Hook, NY, USA. Curran Associates Inc.

**[Evaluating the Moral Beliefs Encoded in LLMs](https://proceedings.neurips.cc/paper_files/paper/2023/file/a2cf225ba392627529efef14dc857e22-Paper-Conference.pdf)**. Nino Scherrer, Claudia Shi, Amir Feder, and David Blei. 2023. In Advances in Neural Information Processing Systems, volume 36, pages 51778–51809. Curran Associates, Inc.  
  
**[NormBank: A Knowledge Bank of Situational Social Norms.](https://doi.org/10.18653/v1/2023.acl-long.429)**. Caleb Ziems, Jane Dwivedi-Yu, Yi-Chia Wang, Alon Halevy, and Diyi Yang. 2023. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7756–7776, Toronto, Canada. Association for Computational Linguistics.

**[SaGE: Evaluating Moral Consistency in Large Language Models.](https://aclanthology.org/2024.lrec-main.1243/)**. Vamshi Krishna Bonagiri, Sreeram Vennam, Priyanshul Govil, Ponnurangam Kumaraguru, and Manas Gaur. 2024. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 14272–14284, Torino, Italia. ELRA and ICCL.
  
**[Position: TrustLLM: Trustworthiness in large language models](https://proceedings.mlr.press/v235/huang24x.html)**. Huang et al. 2024. 2024. In Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 20166–20270. PMLR.

**[EAI: Emotional Decision-Making of LLMs in Strategic Games and Ethical Dilemmas](https://proceedings.neurips.cc/paper_files/paper/2024/file/611e84703eac7cc03f78339df8aae2ed-Paper-Conference.pdf)**. Mikhail Mozikov, Nikita Severin, Valeria Bodishtianu, Maria Glushanina, Ivan Nasonov, Daniil Orekhov, Pekhotin Vladislav, Ivan Makovetskiy, Mikhail Baklashkin, Vasily Lavrentyev, Akim Tsvigun, Denis Turdakov, Tatiana Shavrina, Andrey Savchenko, and Ilya Makarov. 2024. In Advances in Neural Information Processing Systems, volume 37, pages 53969–54002. Curran Associates, Inc.

**[NormAd: A Framework for Measuring the Cultural Adaptability of Large Language Models](http://arxiv.org/abs/2404.12464)**. Abhinav Rao, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, and Maarten Sap. 2024. arXiv:2404.12464v7.
  
### Other Directions in the Creation of Datasets
**[What Would Jiminy Cricket Do? Towards Agents That Behave Morally.](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/39059724f73a9969845dfe4146c5660e-Abstract-round2.html)**. Dan Hendrycks, Mantas Mazeika, Andy Zou, Sahil Patel, Christine Zhu, Jesus Navarro, Dawn Song, Bo Li, and Jacob Steinhardt. 2021c. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, volume 1.

**[Large pre-trained language models contain human-like biases of what is right and wrong to do](https://doi.org/https://doi.org/10.1038/s42256-022-00458-8)**. Patrick Schramowski, Cigdem Turan, Nico Andersen, Constantin A. Rothkopf, and Kristian Kersting. 2022. Nature Machine Intelligence, 4(3):258–268.

**[Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the Machiavelli Benchmark](https://proceedings.mlr.press/v202/pan23a.html)**. Alexander Pan, Jun Shern Chan, Andy Zou, Nathaniel Li, Steven Basart, Thomas Woodside, Hanlin Zhang, Scott Emmons, and Dan Hendrycks. 2023. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 26837–26867. PMLR.

## Repurposed Data Resources
### Moral Foundations Theory (MFT)
#### Resources
**[Who Shalt Not Kill? Individual Differences in Working Memory Capacity, Executive Control, and Moral Judgment](https://doi.org/10.1111/j.1467-9280.2008.02122.x)**. Adam B. Moore, Brian A. Clark, and Michael J. Kane. 2008. Psychological Science, 19(6):549–557.

**[Mapping the Moral Domain](https://doi.org/10.1037/a0021847)**. Jesse Graham, Brian A. Nosek, Jonathan Haidt, Ravi Iyer, Spassena Koleva, and Peter H. Ditto. 2011. Journal of Personality and Social Psychology, 101(2):366–385.  

**[Chapter Two - Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism](https://doi.org/https://doi.org/10.1016/B978-0-12-407236-7.00002-4)**. Jesse Graham, Jonathan Haidt, Sena Koleva, Matt Motyl, Ravi Iyer, Sean P. Wojcik, and Peter H. Ditto. 2013. In Patricia Devine and Ashby Plant, editors, Advances in Experimental Social Psychology, volume 47, pages 55–130. Academic Press.

**[Moral foundations vignettes: a standardized stimulus database of scenarios based on moral foundations theory](https://doi.org/https://doi.org/10.3758/s13428-014-0551-2)**. Scott Clifford, Vijeth Iyengar, Roberto Cabeza, and Walter Sinnott-Armstrong. 2015. Behavior Research Methods, 47(4):1178–1198.
  
**[Multiple moral foundations predict responses to sacrificial dilemmas](https://doi.org/https://doi.org/10.1016/j.paid.2015.04.041)**. Damien L. Crone and Simon M. Laham. 2015. Personality and Individual Differences, 85:60–65.
  
**[Enhancing the Measurement of Social Effects by Capturing Morality](https://doi.org/10.18653/v1/W19-1305)**. Rezvaneh Rezapour, Saumil H. Shah, and Jana Diesner. 2019. In Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 35–45, Minneapolis, USA. Association for Computational Linguistics.

**[MoralFoundations.org](https://moralfoundations.org/)**. 2024. Moral Foundations The
ory.

**[Benchmarking progress in Natural Language Processing applications to Moral Foundations Theory](https://www.mft-nlp.com/)**. MFT-NLP. n.d. Maintained by Gabriel Simmons.

#### Applications
**[Social Chemistry 101: Learning to Reason about Social and Moral Norms](https://doi.org/10.18653/v1/2020.emnlp-main.48)**. Maxwell Forbes, Jena D. Hwang, Vered Shwartz, Maarten Sap, and Yejin Choi. 2020. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 653–670, Online. Association for Computational Linguistics.

**[Does Moral Code have a Moral Code? Probing Delphi’s Moral Philosophy](https://doi.org/10.18653/v1/2022.trustnlp-1.3)**. Kathleen C. Fraser, Svetlana Kiritchenko, and Esma Balkir. 2022. In Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 26–42, Seattle, U.S.A. Association for Computational Linguistics.

**[The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems](https://doi.org/10.18653/v1/2022.acl-long.261)**. Caleb Ziems, Jane Yu, Yi-Chia Wang, Alon Halevy, and Diyi Yang. 2022. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3755–3773, Dublin, Ireland. Association for Computational Linguistics.

**[Speaking Multiple Languages Affects the Moral Bias of Language Models](https://doi.org/10.18653/v1/2023.findings-acl.134)**. Katharina Hämmerl, Bjoern Deiseroth, Patrick Schramowski, Jindˇ rich Libovický, Constantin Rothkopf, Alexander Fraser, and Kristian Kersting. 2023. In Findings of the Association for Computational Linguistics: ACL 2023, pages 2137–2156, Toronto, Canada. Association for Computational Linguistics.

**[Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity](https://doi.org/10.18653/v1/2023.acl-srw.40)**. Gabriel Simmons. 2023. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop), pages 282–297, Toronto, Canada. Association for Computational Linguistics.

**[NormBank: A Knowledge Bank of Situational Social Norms.](https://doi.org/10.18653/v1/2023.acl-long.429)**. Caleb Ziems, Jane Dwivedi-Yu, Yi-Chia Wang, Alon Halevy, and Diyi Yang. 2023. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7756–7776, Toronto, Canada. Association for Computational Linguistics.

**[Moral Foundations of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.982)**. Marwa Abdulhai, Gregory Serapio-García, Clement Crepy, Daria Valter, John Canny, and Natasha Jaques. 2024. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 17737–17752, Miami, Florida, USA. Association for Computational Linguistics.

**[MoralBench: Moral Evaluation of LLMs](http://arxiv.org/abs/2406.04428)**. Jianchao Ji, Yutong Chen, Mingyu Jin, Wujiang Xu, Wenyue Hua, and Yongfeng Zhang. 2024. arXiv:2406.04428.
  
#### Criticisms 
**[Another Look at Moral Foundations Theory: Do Authoritarianism and Social Dominance Orientation Explain Liberal-Conservative Differences in “Moral” Intuitions?](https://doi.org/10.1007/s11211-014-0223-5)**. Matthew Kugler, John T. Jost, and Sharareh Noorbaloochi. 2014. Social Justice Research, 27:413–431.

**[Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity](https://doi.org/10.18653/v1/2023.acl-srw.40)**. Gabriel Simmons. 2023. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop), pages 282–297, Toronto, Canada. Association for Computational Linguistics.

### Kohlberg's Stages of Moral Development
#### Resources
**The Philosophy of Moral Development. Moral Stages and the Idea of Justice, volume 1 of Essays on Moral Development**. Lawrence Kohlberg. 1981. Harper & Row, San Francisco.

**[DIT2: Devising and Testing a Revised Instrument of Moral Judgment](https://psycnet.apa.org/doi/10.1037/0022-0663.91.4.644)**. James R. Rest, Darcia Narvaez, Stephen J. Thoma, and Muriel J. Bebeau. 1999. Journal of Educational Psychology, 91(4):644–659.

#### Applications
**[Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.892)**. Abhinav Sukumar Rao, Aditi Khandelwal, Kumar Tanmay, Utkarsh Agarwal, and Monojit Choudhury. 2023. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 13370–13388, Singapore. Association for Computational Linguistics.

**[Probing the Moral Development of Large Language Models through Defining Issues Test](http://arxiv.org/abs/2309.13356)**. Kumar Tanmay, Aditi Khandelwal, Utkarsh Agarwal, and Monojit Choudhury. 2023. arXiv:2309.13356v2.

**[Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language We Prompt Them in](https://aclanthology.org/2024.lrec-main.560)**. Utkarsh Agarwal, Kumar Tanmay, Aditi Khandelwal, and Monojit Choudhury. 2024. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 6330–6340, Torino, Italia. ELRA and ICCL. 

**[Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test](https://aclanthology.org/2024.eacl-long.176)**. Aditi Khandelwal, Utkarsh Agarwal, Kumar Tanmay, and Monojit Choudhury. 2024. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2882–2894, St. Julian’s, Malta. Association for Computational Linguistics.
  
#### Criticisms 
**[Critiques of Kohlberg’s Model of Moral Development: A Summary](http://www.jstor.org/stable/23765133)**. Paul C. Vitz. 1994. Revista Española de Pedagogía, 52(197):5–35.

### Revised Theory of Modernization
#### Resources
**[Modernization, Cultural Change, and Democracy: The Human Development Sequence](https://doi.org/https://doi.org/10.1017/CBO9780511790881)**. Ronald Inglehart and Christian Welzel. 2005. Cambridge University Press.

**[World Values Survey: Round Seven – Country-Pooled Datafile Version 6.0.0.](https://doi.org/10.14281/18241.24)**. C. Haerpfer, R. Inglehart, A. Moreno, C. Welzel, K. Kizilova, J. Diez-Medrano, M. Lagos, P. Norris, E. Ponarin, and B. Puranen. 2024. JD Systems Institute & WVSA Secretariat, Madrid, Spain & Vienna, Austria.

**[The Cultural Atlas](https://culturalatlas.sbs.com.au/)**. Mosaica. 2025.
  
#### Applications 
**[Probing Pre-Trained Language Models for Cross-Cultural Differences in Values](https://doi.org/10.18653/v1/2023.c3nlp-1.12)**. Arnav Arora, Lucie-aimée Kaffee, and Isabelle Augenstein. 2023. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 114–130, Dubrovnik, Croatia. Association for Computational Linguistics. 

**[Assessing LLMs for Moral Value Pluralism](https://arxiv.org/abs/2312.10075)**. Noam Benkler, Drisana Mosaphir, Scott Friedman, Andrew Smart, and Sonja Schmer-Galunder. 2023. arXiv:2312.10075.

**[Knowledge of cultural moral norms in large language models](https://doi.org/10.18653/v1/2023.acl-long.26)**. Aida Ramezani and Yang Xu. 2023. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 428–446, Toronto, Canada. Association for Computational Linguistics.

**[Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test](https://aclanthology.org/2024.eacl-long.176)**. Aditi Khandelwal, Utkarsh Agarwal, Kumar Tanmay, and Monojit Choudhury. 2024. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2882–2894, St. Julian’s, Malta. Association for Computational Linguistics.

**[NormAd: A Framework for Measuring the Cultural Adaptability of Large Language Models](http://arxiv.org/abs/2404.12464)**. Abhinav Rao, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, and Maarten Sap. 2024. arXiv:2404.12464v7.
  
#### Criticisms 
**[’I with an\[other\]’, otherness and discourse: reconstructing ’democracy’ through inter-cultural education?](https://doi.org/https://doi.org/10.4324/9780429401022)**. Ashley Simpson. 2020. In Fred Dervin, Robyn Moloney, and Ashley Simpson, editors, Intercultural Competence in the Work of Teachers. Confronting Idelogies and Practices, pages 42–56. Routledge. 

### Hofstede's Cultural Dimensions 
#### Resources
**[Dimensionalizing Cultures: The Hofstede Model in Context](https://doi.org/10.9707/2307-0919.1014)**. Geert Hofstede. 2011. Online Readings in Psychology and Culture, 2(1).

**[VALUES SURVEY MODULE 2013 MANUAL](https://geerthofstede.com/wp-content/uploads/2016/07/Manual-VSM-2013.pdf)**. Geert Hofstede and Michael Minkov. 2013a. VSM 2013. Geert Hofstede BV.

**[VALUES SURVEY MODULE 2013 QUESTIONNAIRE. English language version.](https://geerthofstede.com/wp-content/uploads/2016/07/VSM-2013-English-2013-08-25.pdf)**. Geert Hofstede and Michael Minkov. 2013b. VSM 2013.

#### Applications
**[Probing Pre-Trained Language Models for Cross-Cultural Differences in Values](https://doi.org/10.18653/v1/2023.c3nlp-1.12)**. Arnav Arora, Lucie-aimée Kaffee, and Isabelle Augenstein. 2023. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 114–130, Dubrovnik, Croatia. Association for Computational Linguistics. 

### Schwartz' Theory of Basic Values
#### Resources 
**[The Human Values Scale: Findings from the European Social Survey](https://www.europeansocialsurvey.org/sites/default/files/2023-06/ESS_Findings_HVS.pdf)**. European Social Survey. 2021. ESS-ERIC.

**[Measuring the Refined Theory of Individual Values in 49 Cultural Groups: Psychometrics of the Revised Portrait Value Questionnaire](https://doi.org/10.1177/1073191121998760)**. Shalom H. Schwartz and Jan Cieciuch. 2022. Assessment, 29(5):1005–1019.

#### Applications 
**[Who is GPT-3? An exploration of personality, values and demographics](https://doi.org/10.18653/v1/2022.nlpcss-1.24)**. Marilù Miotto, Nicola Rossberg, and Bennett Kleinberg. 2022. In Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS), pages 218–227, Abu Dhabi, UAE. Association for Computational Linguistics.

**[Embedded values-like shape ethical reasoning of large language models on primary care ethical dilemmas](https://doi.org/https://doi.org/10.1016/j.heliyon.2024.e38056)**. Dorit Hadar-Shoval, Kfir Asraf, Shiri Shinan-Altman, Zohar Elyoseph, and Inbar Levkovich. 2024. Heliyon, 10(18):e38056.
  
### Other Resources
**[The Community, Autonomy, and Divinity Scale (CADS): A New Tool for the Cross-Cultural Study of Morality](https://doi.org/10.1177/0022022109348919)**. Valeschka M. Guerra and Roger Giner-Sorolla. 2010. Journal of Cross-Cultural Psychology, 41(1):35–50.

**[Beyond Sacrificial Harm: A Two-Dimensional Model of Utilitarian Psychology](https://doi.org/10.1037/rev0000093)**. Guy Kahane, Jim A. C. Everett, Brian D. Earp, Lucius Caviola, Nadira S. Faber, Molly J. Crockett, and Julian Savulescu. 2018. Psychological Review, 125(2):131–164.

**[When to make exceptions: exploring language models as accounts of human moral judgment](https://dl.acm.org/doi/10.5555/3600270.3602333)**. Zhijing Jin, Sydney Levine, Fernando Gonzalez, Ojasv Kamal, Maarten Sap, Mrinmaya Sachan, Rada Mihalcea, Joshua Tenenbaum, and Bernhard Schölkopf. 2022. In Proceedings of the 36th International Conference on Neural Information Processing Systems, NeurIPS ’22, Red Hook, NY, USA. Curran Associates Inc. 

**[Deontology and utilitarianism in real life: A set of moral dilemmas based on historic events](https://doi.org/10.1177/01461672221103058)**. Anita Körner and Roland Deutsch. 2023. Personality and Social Psychology Bulletin, 49(10):1511–1528.

**[A reinforcement-learning meta-control architecture based on the dual-process theory of moral decision-making](https://neurips.cc/virtual/2023/workshop/66528)**. Maximilian Maier, Vanessa Cheung, and Falk Lieder. 2023. AI meets Moral Philosophy and Moral Psychology, NeurIPS 2023.

**[MoCa: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks](https://proceedings.neurips.cc/paper_files/paper/2023/file/f751c6f8bfb52c60f43942896fe65904-Paper-Conference.pdf)**. Allen Nie, Yuhui Zhang, Atharva Shailesh Amdekar, Chris Piech, Tatsunori B Hashimoto, and Tobias Gerstenberg. 2023. In Advances in Neural Information Processing Systems, volume 36, pages 78360–78393. Curran Associates, Inc.
  
### Moral Consistency & Certainty
#### Logical Consistency
**[Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.892)**. Abhinav Sukumar Rao, Aditi Khandelwal, Kumar Tanmay, Utkarsh Agarwal, and Monojit Choudhury. 2023. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 13370–13388, Singapore. Association for Computational Linguistics.

**[Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language We Prompt Them in](https://aclanthology.org/2024.lrec-main.560)**. Utkarsh Agarwal, Kumar Tanmay, Aditi Khandelwal, and Monojit Choudhury. 2024. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 6330–6340, Torino, Italia. ELRA and ICCL. 

#### Semantic Consistency
**[SaGE: Evaluating Moral Consistency in Large Language Models.](https://aclanthology.org/2024.lrec-main.1243/)**. Vamshi Krishna Bonagiri, Sreeram Vennam, Priyanshul Govil, Ponnurangam Kumaraguru, and Manas Gaur. 2024. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 14272–14284, Torino, Italia. ELRA and ICCL.

#### Moral Certainty
**[Evaluating the Moral Beliefs Encoded in LLMs](https://proceedings.neurips.cc/paper_files/paper/2023/file/a2cf225ba392627529efef14dc857e22-Paper-Conference.pdf)**. Nino Scherrer, Claudia Shi, Amir Feder, and David Blei. 2023. In Advances in Neural Information Processing Systems, volume 36, pages 51778–51809. Curran Associates, Inc.

**[Towards Theory-based Moral AI: Moral AI with Aggregating Models Based on Normative Ethical Theory](https://ceur-ws.org/Vol-3547/paper3.pdf)**. Masashi Takeshita, Rzepka Rafal, and Kenji Araki. 2023. In Ethics and Trust in Human-AI Collaboration: Socio-Technical Approaches, August 21, 2023, Macao, China. CEUR Workshop Proceedings.

**[EAI: Emotional Decision-Making of LLMs in Strategic Games and Ethical Dilemmas](https://proceedings.neurips.cc/paper_files/paper/2024/file/611e84703eac7cc03f78339df8aae2ed-Paper-Conference.pdf)**. Mikhail Mozikov, Nikita Severin, Valeria Bodishtianu, Maria Glushanina, Ivan Nasonov, Daniil Orekhov, Pekhotin Vladislav, Ivan Makovetskiy, Mikhail Baklashkin, Vasily Lavrentyev, Akim Tsvigun, Denis Turdakov, Tatiana Shavrina, Andrey Savchenko, and Ilya Makarov. 2024. In Advances in Neural Information Processing Systems, volume 37, pages 53969–54002. Curran Associates, Inc.  

### Methodological Guidelines 
**[Handbook of Survey Methodology for the Social Sciences](https://doi.org/10.1007/978-1-4614-3876-2)**. Lior Gideon, editor. 2012. Springer, New York, NY.

**[Designing Valid and Reliable Vignette Experiments for Survey Research: A Case Study on the Fair Gender Income Gap](https://doi.org/10.2458/v7i2.20321)**. Peter M. Steiner, Christiane Atzmüller, and Dan Su. 2017. Journal of Methods and Measurement in the Social Sciences, 7:52–94.

**[Challenges and Strategies in Cross-Cultural NLP](https://doi.org/10.18653/v1/2022.acl-long.482)**. Daniel Hershcovich, Stella Frank, Heather Lent, Miryam de Lhoneux, Mostafa Abdou, Stephanie Brandl, Emanuele Bugliarello, Laura Cabello Piqueras, Ilias Chalkidis, Ruixiang Cui, Constanza Fierro, Katerina Margatina, Phillip Rust, and Anders Søgaard. 2022. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6997–7013, Dublin, Ireland. Association for Computational Linguistics.

**[Whose Opinions Do Language Models Reflect?](https://proceedings.mlr.press/v202/santurkar23a.html)**. Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, and Tatsunori Hashimoto. 2023. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 29971–30004. PMLR. 
